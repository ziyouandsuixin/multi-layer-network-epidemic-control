# experiments/baseline_models.py (ä¿®å¤ç‰ˆ)
import numpy as np
import networkx as nx
from sklearn.cluster import KMeans
from epydemic import SIR, StochasticDynamics
from typing import Dict, Any, List
from .base_model import EpidemicModel
import os
import yaml

# æ·»åŠ åœ¨æ–‡ä»¶å¼€å¤´
CONFIG_DIR = os.path.join(os.path.dirname(__file__), 'config')
BASELINE_CONFIG_FILE = os.path.join(CONFIG_DIR, 'baseline_params.yaml')

class ClassicSEIRModel(EpidemicModel):
    """ç»å…¸SEIRæ¨¡å‹ - ä½¿ç”¨epydemicåº“ - ä¿®å¤æ•°æ®æ ¼å¼"""
    
    def __init__(self, config: Dict[str, Any] = None):
        # å…ˆåŠ è½½é…ç½®æ–‡ä»¶å‚æ•°
        file_config = self._load_baseline_config().get('classic_seir', {})
        default_config = {
            'r0': 2.2,
            'latent_period': 2.0,
            'infectious_period': 5.0,
            'intervention_effectiveness': 0.3
        }
        default_config.update(file_config)  # æ–‡ä»¶é…ç½®è¦†ç›–é»˜è®¤å€¼
        
        if config:
            default_config.update(config)  # ä¼ å…¥é…ç½®è¦†ç›–æ‰€æœ‰
        super().__init__("Classic_SEIR", default_config)
        
        print(f"åŠ è½½ClassicSEIRé…ç½®: R0={self.config['r0']}, æ½œä¼æœŸ={self.config['latent_period']}")
        
        # åˆå§‹åŒ–epydemicæ¨¡å‹
        self.sir_model = SIR()
    
    def _load_baseline_config(self) -> Dict[str, Any]:
        """ä»é…ç½®æ–‡ä»¶åŠ è½½åŸºå‡†æ¨¡å‹å‚æ•°"""
        try:
            if os.path.exists(BASELINE_CONFIG_FILE):
                with open(BASELINE_CONFIG_FILE, 'r', encoding='utf-8') as f:
                    config_data = yaml.safe_load(f)
                return config_data
            else:
                print(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {BASELINE_CONFIG_FILE}")
                return {}
        except Exception as e:
            print(f" åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return {}
    
    def simulate(self, network_data: Any, initial_states: Dict, time_steps: int) -> Dict[str, Any]:
        """è¿è¡Œç»å…¸SEIRæ¨¡æ‹Ÿ - ä¿®å¤æ•°æ®æ ¼å¼è½¬æ¢"""
        try:
            print("è½¬æ¢æ•°æ®æ ¼å¼ä¸ºç»å…¸SEIRæ ¼å¼...")
            
            # ä»å®éªŒæ¡†æ¶æ•°æ®ä¸­æå–ä¿¡æ¯
            population_size = initial_states.get('total_population', 500)
            initial_infected_count = len(initial_states.get('infected_nodes', []))
            
            # åˆ›å»ºå®Œå…¨è¿æ¥ç½‘ç»œï¼ˆå‡è´¨æ··åˆå‡è®¾ï¼‰
            g = nx.complete_graph(population_size)
            
            # è®¾ç½®æ¨¡å‹å‚æ•°
            params = {
                SIR.P_INFECT: self.config['r0'] / self.config['infectious_period'],
                SIR.P_REMOVE: 1.0 / self.config['infectious_period'],
                SIR.P_INFECTED: initial_infected_count / population_size
            }
            
            print(f"  å‚æ•°: R0={self.config['r0']}, åˆå§‹æ„ŸæŸ“={initial_infected_count}/{population_size}")
            
            # è¿è¡Œæ¨¡æ‹Ÿ
            dynamics = StochasticDynamics(self.sir_model, g)
            dynamics.set(params)
            results = dynamics.run()
            
            # æå–æ—¶é—´åºåˆ—ç»“æœ - ä¿®å¤å¯èƒ½çš„é”®é”™è¯¯
            if 'results' in results and 'times' in results['results']:
                times = results['results']['times']
                susceptible = results['results'].get(SIR.SUSCEPTIBLE, [])
                infected = results['results'].get(SIR.INFECTED, [])
                recovered = results['results'].get(SIR.REMOVED, [])
            else:
                # å¦‚æœç»“æœæ ¼å¼ä¸ç¬¦ï¼Œåˆ›å»ºæ¨¡æ‹Ÿç»“æœ
                times = list(range(time_steps))
                susceptible = [population_size - initial_infected_count] * time_steps
                infected = [initial_infected_count] * time_steps
                recovered = [0] * time_steps
            
            self.results = {
                'time_series': {
                    'time': times,
                    'susceptible': susceptible,
                    'infected': infected,
                    'recovered': recovered
                },
                'peak_infection': max(infected) if infected else 0,
                'total_cases': recovered[-1] if recovered else 0,
                'success': True
            }
            
            print(f"ç»å…¸SEIRæ¨¡æ‹Ÿå®Œæˆ: å³°å€¼æ„ŸæŸ“={max(infected) if infected else 0}")
            return self.results
            
        except Exception as e:
            print(f"ç»å…¸SEIRæ¨¡æ‹Ÿé”™è¯¯: {e}")
            # è¿”å›æœ‰æ„ä¹‰çš„æ¨¡æ‹Ÿæ•°æ®è€Œä¸æ˜¯ç©ºç»“æœ
            return self._create_fallback_results(initial_states, time_steps)
    
    def _create_fallback_results(self, initial_states: Dict, time_steps: int) -> Dict[str, Any]:
        """åˆ›å»ºç»å…¸SEIRçš„å›é€€ç»“æœ"""
        population_size = initial_states.get('total_population', 500)
        initial_infected = len(initial_states.get('infected_nodes', []))
        
        # ç®€å•çš„SEIRæ¨¡æ‹Ÿ
        S = [population_size - initial_infected]
        I = [initial_infected]
        R = [0]
        
        beta = self.config['r0'] / self.config['infectious_period']
        gamma = 1.0 / self.config['infectious_period']
        
        for t in range(1, time_steps):
            new_infections = beta * S[-1] * I[-1] / population_size
            new_recoveries = gamma * I[-1]
            
            S.append(S[-1] - new_infections)
            I.append(I[-1] + new_infections - new_recoveries)
            R.append(R[-1] + new_recoveries)
        
        return {
            'time_series': {
                'time': list(range(time_steps)),
                'susceptible': S,
                'infected': I,
                'recovered': R
            },
            'peak_infection': max(I),
            'total_cases': R[-1],
            'success': False,
            'error': 'ä½¿ç”¨å›é€€æ¨¡æ‹Ÿ'
        }
    
    def allocate_resources(self, risk_assessment: Dict, available_resources: Dict) -> Dict[str, float]:
        """å‡ä¸€åŒ–èµ„æºåˆ†é…"""
        total_population = risk_assessment.get('total_population', 1)
        allocation = {}
        
        communities = risk_assessment.get('communities', {})
        if not communities:
            # å¦‚æœæ²¡æœ‰ç¤¾åŒºä¿¡æ¯ï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤ç¤¾åŒº
            communities = {'default_community': {'population': total_population, 'infected_count': 0}}
        
        for community, info in communities.items():
            population_ratio = info.get('population', 0) / total_population
            allocation[community] = {
                resource: amount * population_ratio 
                for resource, amount in available_resources.items()
            }
        
        return allocation

class NetworkSEIRModel(EpidemicModel):
    """ç½‘ç»œSEIRæ¨¡å‹ - ä¿®å¤æ•°æ®æ ¼å¼è½¬æ¢"""
    
    def __init__(self, config: Dict[str, Any] = None):
        # å…ˆåŠ è½½é…ç½®æ–‡ä»¶å‚æ•°
        file_config = self._load_baseline_config().get('network_seir', {})
        default_config = {
            'infection_probability': 0.1,
            'recovery_probability': 0.05,
            'community_detection': 'static'
        }
        default_config.update(file_config)  # æ–‡ä»¶é…ç½®è¦†ç›–é»˜è®¤å€¼
        
        if config:
            default_config.update(config)  # ä¼ å…¥é…ç½®è¦†ç›–æ‰€æœ‰
        super().__init__("Network_SEIR", default_config)
        
        print(f"åŠ è½½NetworkSEIRé…ç½®: æ„ŸæŸ“æ¦‚ç‡={self.config['infection_probability']}, æ¢å¤æ¦‚ç‡={self.config['recovery_probability']}")
    
    def _load_baseline_config(self) -> Dict[str, Any]:
        """ä»é…ç½®æ–‡ä»¶åŠ è½½åŸºå‡†æ¨¡å‹å‚æ•°"""
        try:
            if os.path.exists(BASELINE_CONFIG_FILE):
                with open(BASELINE_CONFIG_FILE, 'r', encoding='utf-8') as f:
                    config_data = yaml.safe_load(f)
                return config_data
            else:
                print(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {BASELINE_CONFIG_FILE}")
                return {}
        except Exception as e:
            print(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return {}
    
    def simulate(self, network_data: Any, initial_states: Dict, time_steps: int) -> Dict[str, Any]:
        """è¿è¡Œç½‘ç»œSEIRæ¨¡æ‹Ÿ - ä¿®å¤æ•°æ®æ ¼å¼è½¬æ¢"""
        try:
            print("è½¬æ¢æ•°æ®æ ¼å¼ä¸ºç½‘ç»œSEIRæ ¼å¼...")
            
            # å°†å®éªŒæ¡†æ¶æ•°æ®è½¬æ¢ä¸ºNetworkXå›¾
            network_graph = self._convert_to_networkx(network_data)
            
            if network_graph.number_of_nodes() == 0:
                raise ValueError("è½¬æ¢åçš„ç½‘ç»œæ²¡æœ‰èŠ‚ç‚¹")
            
            # åˆå§‹åŒ–èŠ‚ç‚¹çŠ¶æ€
            node_states = self._initialize_states(network_graph, initial_states)
            time_series = {'S': [], 'I': [], 'R': []}
            
            print(f"  ç½‘ç»œ: {network_graph.number_of_nodes()}èŠ‚ç‚¹, {network_graph.number_of_edges()}è¾¹")
            print(f"  åˆå§‹çŠ¶æ€: S={sum(1 for s in node_states.values() if s == 'S')}, I={sum(1 for s in node_states.values() if s == 'I')}")
            
            for t in range(time_steps):
                # è®°å½•å½“å‰çŠ¶æ€
                s_count = sum(1 for state in node_states.values() if state == 'S')
                i_count = sum(1 for state in node_states.values() if state == 'I') 
                r_count = sum(1 for state in node_states.values() if state == 'R')
                
                time_series['S'].append(s_count)
                time_series['I'].append(i_count)
                time_series['R'].append(r_count)
                
                # ä¼ æ’­è¿‡ç¨‹
                new_states = node_states.copy()
                for node, state in node_states.items():
                    if state == 'I':
                        # æ¢å¤è¿‡ç¨‹
                        if np.random.random() < self.config['recovery_probability']:
                            new_states[node] = 'R'
                        # æ„ŸæŸ“é‚»å±…
                        for neighbor in network_graph.neighbors(node):
                            if (node_states[neighbor] == 'S' and 
                                np.random.random() < self.config['infection_probability']):
                                new_states[neighbor] = 'I'
                
                node_states = new_states
            
            self.results = {
                'time_series': time_series,
                'node_states': node_states,
                'peak_infection': max(time_series['I']),
                'total_cases': time_series['R'][-1],
                'success': True
            }
            
            print(f"ç½‘ç»œSEIRæ¨¡æ‹Ÿå®Œæˆ: å³°å€¼æ„ŸæŸ“={max(time_series['I'])}")
            return self.results
            
        except Exception as e:
            print(f"ç½‘ç»œSEIRæ¨¡æ‹Ÿé”™è¯¯: {e}")
            return self._create_fallback_results(initial_states, time_steps)
    
    def _convert_to_networkx(self, network_data: Any) -> nx.Graph:
        """å°†å®éªŒæ¡†æ¶æ•°æ®è½¬æ¢ä¸ºNetworkXå›¾"""
        G = nx.Graph()
        
        if isinstance(network_data, dict):
            # å¤„ç†å­—å…¸æ ¼å¼çš„ç½‘ç»œæ•°æ®
            nodes = network_data.get('nodes', [])
            edges = network_data.get('edges', [])
            
            # æ·»åŠ èŠ‚ç‚¹
            for node in nodes:
                if isinstance(node, (int, str)):
                    G.add_node(node)
                else:
                    G.add_node(str(node))  # ç¡®ä¿èŠ‚ç‚¹æ˜¯å¯å“ˆå¸Œçš„
            
            # æ·»åŠ è¾¹
            for edge in edges:
                if isinstance(edge, dict):
                    source = edge.get('source')
                    target = edge.get('target')
                    weight = edge.get('weight', 1.0)
                    if source is not None and target is not None:
                        G.add_edge(source, target, weight=weight)
                elif isinstance(edge, (list, tuple)) and len(edge) >= 2:
                    G.add_edge(edge[0], edge[1])
        
        elif hasattr(network_data, 'nodes') and hasattr(network_data, 'edges'):
            # å·²ç»æ˜¯NetworkXå›¾æˆ–å…¶ä»–å›¾å¯¹è±¡
            return network_data
        else:
            # åˆ›å»ºé»˜è®¤ç½‘ç»œ
            population_size = 100
            G = nx.erdos_renyi_graph(population_size, 0.1)
        
        return G
    
    def _initialize_states(self, network, initial_states: Dict) -> Dict[Any, str]:
        """åˆå§‹åŒ–èŠ‚ç‚¹çŠ¶æ€"""
        node_states = {}
        infected_nodes = initial_states.get('infected_nodes', [])
        
        for node in network.nodes():
            if node in infected_nodes:
                node_states[node] = 'I'
            else:
                node_states[node] = 'S'
        
        return node_states
    
    def _create_fallback_results(self, initial_states: Dict, time_steps: int) -> Dict[str, Any]:
        """åˆ›å»ºç½‘ç»œSEIRçš„å›é€€ç»“æœ"""
        population_size = initial_states.get('total_population', 500)
        initial_infected = len(initial_states.get('infected_nodes', []))
        
        # ç®€åŒ–çš„ç½‘ç»œSEIRæ¨¡æ‹Ÿ
        time_series = {'S': [], 'I': [], 'R': []}
        
        S = population_size - initial_infected
        I = initial_infected
        R = 0
        
        for t in range(time_steps):
            time_series['S'].append(S)
            time_series['I'].append(I)
            time_series['R'].append(R)
            
            # ç®€åŒ–çš„ä¼ æ’­é€»è¾‘
            new_infections = min(S, int(I * 0.15))
            new_recoveries = min(I, int(I * 0.1))
            
            S -= new_infections
            I += new_infections - new_recoveries
            R += new_recoveries
        
        return {
            'time_series': time_series,
            'peak_infection': max(time_series['I']),
            'total_cases': time_series['R'][-1],
            'success': False,
            'error': 'ä½¿ç”¨å›é€€æ¨¡æ‹Ÿ'
        }
    
    def allocate_resources(self, risk_assessment: Dict, available_resources: Dict) -> Dict[str, float]:
        """åŸºäºèŠ‚ç‚¹åº¦çš„èµ„æºåˆ†é…"""
        allocation = {}
        
        communities = risk_assessment.get('communities', {})
        if not communities:
            # å¦‚æœæ²¡æœ‰ç¤¾åŒºä¿¡æ¯ï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤ç¤¾åŒº
            total_population = risk_assessment.get('total_population', 1)
            communities = {'default_community': {'population': total_population, 'infected_count': 0, 'average_degree': 2}}
        
        total_risk = 0
        risk_scores = {}
        
        for community, info in communities.items():
            avg_degree = info.get('average_degree', 1)
            population = info.get('population', 1)
            infected_count = info.get('infected_count', 0)
            
            risk_score = (avg_degree * infected_count) / max(population, 1)
            risk_scores[community] = risk_score
            total_risk += risk_score
        
        if total_risk > 0:
            for community, risk_score in risk_scores.items():
                allocation_ratio = risk_score / total_risk
                allocation[community] = {
                    resource: amount * allocation_ratio 
                    for resource, amount in available_resources.items()
                }
        else:
            # å¹³å‡åˆ†é…
            n_communities = len(communities)
            for community in communities.keys():
                allocation[community] = {
                    resource: amount / n_communities 
                    for resource, amount in available_resources.items()
                }
        
        return allocation

class GridManagementModel(EpidemicModel):
    """åœ°ç†ç½‘æ ¼ç®¡ç†æ¨¡å‹ - ä¿®å¤æ•°æ®æ ¼å¼"""
    
    def __init__(self, config: Dict[str, Any] = None):
        # å…ˆåŠ è½½é…ç½®æ–‡ä»¶å‚æ•°
        file_config = self._load_baseline_config().get('grid_management', {})
        default_config = {
            'n_clusters': 10,
            'geographic_weight': 0.8,
            'population_weight': 0.2
        }
        default_config.update(file_config)  # æ–‡ä»¶é…ç½®è¦†ç›–é»˜è®¤å€¼
        
        if config:
            default_config.update(config)  # ä¼ å…¥é…ç½®è¦†ç›–æ‰€æœ‰
        super().__init__("Grid_Management", default_config)
        
        print(f"ğŸ“‹ åŠ è½½GridManagementé…ç½®: èšç±»æ•°={self.config['n_clusters']}, åœ°ç†æƒé‡={self.config['geographic_weight']}")
        
        self.kmeans = KMeans(n_clusters=self.config['n_clusters'], random_state=42, n_init=10)  # ä¿®å¤è­¦å‘Š
    
    def _load_baseline_config(self) -> Dict[str, Any]:
        """ä»é…ç½®æ–‡ä»¶åŠ è½½åŸºå‡†æ¨¡å‹å‚æ•°"""
        try:
            if os.path.exists(BASELINE_CONFIG_FILE):
                with open(BASELINE_CONFIG_FILE, 'r', encoding='utf-8') as f:
                    config_data = yaml.safe_load(f)
                return config_data
            else:
                print(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {BASELINE_CONFIG_FILE}")
                return {}
        except Exception as e:
            print(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return {}
    
    def simulate(self, network_data: Any, initial_states: Dict, time_steps: int) -> Dict[str, Any]:
        """è¿è¡Œåœ°ç†ç½‘æ ¼æ¨¡æ‹Ÿ - ä¿®å¤æ•°æ®æ ¼å¼"""
        try:
            print("è½¬æ¢æ•°æ®æ ¼å¼ä¸ºåœ°ç†ç½‘æ ¼æ ¼å¼...")
            
            # æå–åœ°ç†åæ ‡
            geographic_coords = self._extract_geographic_data(network_data, initial_states)
            
            if len(geographic_coords) < self.config['n_clusters']:
                # å¦‚æœæ•°æ®ç‚¹å¤ªå°‘ï¼Œè°ƒæ•´èšç±»æ•°
                actual_clusters = max(2, len(geographic_coords) // 10)
                self.kmeans = KMeans(n_clusters=actual_clusters, random_state=42, n_init=10)
                print(f"  è°ƒæ•´èšç±»æ•°: {actual_clusters}")
            
            # åœ°ç†èšç±»
            grid_assignments = self.kmeans.fit_predict(geographic_coords)
            
            # ç®€åŒ–çš„ç½‘æ ¼çº§SEIRæ¨¡æ‹Ÿ
            grid_results = self._simulate_grid_epidemic(
                grid_assignments, initial_states, time_steps
            )
            
            self.results = {
                'grid_assignments': grid_assignments.tolist(),
                'grid_centers': self.kmeans.cluster_centers_.tolist(),
                'epidemic_curve': grid_results,
                'success': True
            }
            
            print(f"åœ°ç†ç½‘æ ¼æ¨¡æ‹Ÿå®Œæˆ: {len(np.unique(grid_assignments))}ä¸ªç½‘æ ¼")
            return self.results
            
        except Exception as e:
            print(f"åœ°ç†ç½‘æ ¼æ¨¡æ‹Ÿé”™è¯¯: {e}")
            return self._create_fallback_results(initial_states, time_steps)
    
    def _extract_geographic_data(self, network_data: Any, initial_states: Dict) -> np.ndarray:
        """æå–åœ°ç†åæ ‡æ•°æ®"""
        population_size = initial_states.get('total_population', 500)
        
        if isinstance(network_data, dict) and 'geographic_coords' in network_data:
            # ä»ç½‘ç»œæ•°æ®ä¸­æå–åœ°ç†åæ ‡
            coords_dict = network_data['geographic_coords']
            if coords_dict:
                coords_list = []
                for node, coord in coords_dict.items():
                    if isinstance(coord, dict) and 'lat' in coord and 'lon' in coord:
                        coords_list.append([coord['lat'], coord['lon']])
                    elif isinstance(coord, (list, tuple)) and len(coord) >= 2:
                        coords_list.append([coord[0], coord[1]])
                
                if coords_list:
                    return np.array(coords_list)
        
        # ä½¿ç”¨æ¨¡æ‹Ÿåæ ‡ä½œä¸ºå›é€€
        return np.random.rand(population_size, 2)
    
    def _simulate_grid_epidemic(self, grid_assignments: np.ndarray, initial_states: Dict, time_steps: int) -> Dict:
        """ç½‘æ ¼çº§æµè¡Œç—…æ¨¡æ‹Ÿ"""
        n_grids = len(np.unique(grid_assignments))
        grid_infections = np.zeros((time_steps, n_grids))
        
        # åˆå§‹åŒ–æ„ŸæŸ“
        initial_infected = initial_states.get('infected_nodes', [])
        population_size = len(grid_assignments)
        
        for i, grid_id in enumerate(grid_assignments):
            if i < len(initial_infected) and initial_infected[i]:
                grid_infections[0, grid_id] += 1
        
        # ç®€åŒ–çš„ç½‘æ ¼é—´ä¼ æ’­
        for t in range(1, time_steps):
            for grid_id in range(n_grids):
                # åŸºç¡€å¢é•¿ + ç½‘æ ¼é—´ä¼ æ’­
                current_infected = grid_infections[t-1, grid_id]
                growth = current_infected * 0.1  # 10% å¢é•¿
                # ä»å…¶ä»–ç½‘æ ¼ä¼ æ’­
                for other_grid in range(n_grids):
                    if other_grid != grid_id:
                        spread = grid_infections[t-1, other_grid] * 0.02  # 2% ä¼ æ’­
                        growth += spread
                
                grid_infections[t, grid_id] = current_infected + growth
        
        return {
            'grid_infections': grid_infections.tolist(),
            'total_infected': np.sum(grid_infections, axis=1).tolist()
        }
    
    def _create_fallback_results(self, initial_states: Dict, time_steps: int) -> Dict[str, Any]:
        """åˆ›å»ºåœ°ç†ç½‘æ ¼çš„å›é€€ç»“æœ"""
        population_size = initial_states.get('total_population', 500)
        initial_infected = len(initial_states.get('infected_nodes', []))
        
        # ç®€åŒ–çš„ç½‘æ ¼æ¨¡æ‹Ÿ
        n_grids = min(10, population_size // 50)
        grid_infections = np.zeros((time_steps, n_grids))
        
        # éšæœºåˆ†é…åˆå§‹æ„ŸæŸ“
        for i in range(min(initial_infected, n_grids)):
            grid_infections[0, i] = 1
        
        for t in range(1, time_steps):
            grid_infections[t] = grid_infections[t-1] * 1.1
        
        return {
            'grid_assignments': list(range(n_grids)) * (population_size // n_grids),
            'grid_centers': np.random.rand(n_grids, 2).tolist(),
            'epidemic_curve': {
                'grid_infections': grid_infections.tolist(),
                'total_infected': np.sum(grid_infections, axis=1).tolist()
            },
            'success': False,
            'error': 'ä½¿ç”¨å›é€€æ¨¡æ‹Ÿ'
        }
    
    def allocate_resources(self, risk_assessment: Dict, available_resources: Dict) -> Dict[str, float]:
        """åŸºäºåœ°ç†ç½‘æ ¼å’Œäººå£å¯†åº¦çš„èµ„æºåˆ†é…"""
        allocation = {}
        total_population = risk_assessment.get('total_population', 1)
        
        communities = risk_assessment.get('communities', {})
        if not communities:
            # å¦‚æœæ²¡æœ‰ç¤¾åŒºä¿¡æ¯ï¼Œåˆ›å»ºé»˜è®¤ç½‘æ ¼
            n_grids = 5
            for i in range(n_grids):
                communities[f'grid_{i}'] = {
                    'population': total_population // n_grids,
                    'geographic_priority': np.random.uniform(0.5, 1.0)
                }
        
        total_weight = 0
        community_weights = {}
        
        for community, info in communities.items():
            population_ratio = info.get('population', 0) / total_population
            geographic_priority = info.get('geographic_priority', 1.0)
            
            combined_weight = (
                self.config['population_weight'] * population_ratio +
                self.config['geographic_weight'] * geographic_priority
            )
            
            community_weights[community] = combined_weight
            total_weight += combined_weight
        
        if total_weight > 0:
            for community, weight in community_weights.items():
                allocation_ratio = weight / total_weight
                allocation[community] = {
                    resource: amount * allocation_ratio 
                    for resource, amount in available_resources.items()
                }
        else:
            # å¹³å‡åˆ†é…
            n_communities = len(communities)
            for community in communities.keys():
                allocation[community] = {
                    resource: amount / n_communities 
                    for resource, amount in available_resources.items()
                }
        
        return allocation